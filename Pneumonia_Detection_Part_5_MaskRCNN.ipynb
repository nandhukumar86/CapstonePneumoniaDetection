{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsO7UuEaxKGu",
    "outputId": "49eee4bd-42d4-4f45-b0ca-15c731ea2e8a"
   },
   "outputs": [],
   "source": [
    "#MASK rcnn-objcect detection\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SGX3Tmbvxgub"
   },
   "outputs": [],
   "source": [
    "#TrainDir = \"/content/drive/MyDrive/Content/DriveAIML/capstone/jpg_reshaped_train/\"\n",
    "#TestDir='/content/drive/MyDrive/Content/DriveAIML/capstone/jpg_reshaped_test/'\n",
    "#sublabel='/content/drive/MyDrive/Content/DriveAIML/capstone/stage_2_sample_submission.csv'\n",
    "#basepath = \"/content/drive/MyDrive/Content/DriveAIML/capstone/\"\n",
    "\n",
    "#local path\n",
    "TrainDir = 'C:/Users/vao5kor/Desktop/Python/olympus/Capstone project/rsna-pneumonia-detection-challenge/jpg_reshaped_train/'\n",
    "TestDir='C:/Users/vao5kor/Desktop/Python/olympus/Capstone project/rsna-pneumonia-detection-challenge/jpg_reshaped_test/'\n",
    "sublabel='C:/Users/vao5kor/Desktop/Python/olympus/Capstone project/rsna-pneumonia-detection-challenge/stage_2_sample_submission.csv'\n",
    "basepath = \"C:/Users/vao5kor/Desktop/Python/olympus/Capstone project/rsna-pneumonia-detection-challenge/\"\n",
    "modeldir = 'C:/Users/vao5kor/Downloads/Mask_RCNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TgBJfzkPxg-C"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'glob2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8c03dc67363f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mglob2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'glob2'"
     ]
    }
   ],
   "source": [
    "import os, cv2,copy, gc\n",
    "import pickle\n",
    "import glob2 as glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, Model, losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation, BatchNormalization\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.variable_scope()\n",
    "#tf.compat.v1.variable_scope()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rj8yJcN5xj5S"
   },
   "outputs": [],
   "source": [
    "filename =  basepath+'RezisedLabel.pickle'\n",
    "with open(filename, \"rb\") as input_file:\n",
    "  y_train = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knB88o1_1Aaf"
   },
   "outputs": [],
   "source": [
    "#trainimg = glob.glob(TrainDir+'*.jpg') #Getting all images in this folder\n",
    "#testimg=glob.glob(TestDir+\"*.jpg\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bE9CPavU1ZlB",
    "outputId": "c7126817-eab1-45a9-f3f2-4fe942f3d2c6"
   },
   "outputs": [],
   "source": [
    " #len(trainimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "HuyrHg4Rxj-n",
    "outputId": "63f6a544-23be-465b-eb6d-07c746f9bab3"
   },
   "outputs": [],
   "source": [
    "y_train.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCDe0iyyxkB6",
    "outputId": "135d4555-8e0c-4249-8f95-066cbba071e4"
   },
   "outputs": [],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMJ62ehhyZD8"
   },
   "outputs": [],
   "source": [
    "class_info_df = pd.read_csv(basepath+'stage_2_detailed_class_info.csv')\n",
    "sub_info_df=pd.read_csv(sublabel)#test label or submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "SVcIkN_JyZHb",
    "outputId": "334340c9-6b79-425a-93d1-a22661acbc37"
   },
   "outputs": [],
   "source": [
    "## Merging the two datasets\n",
    "#In class detailed info dataset are given the detailed information about \n",
    "#the type of positive or negative class associated with a certain patient.\n",
    "#In y_train labels dataset are given the patient ID and the window (x min, y min, width and height of the) \n",
    "#containing evidence of pneumonia\n",
    "train_class_df = y_train.merge(class_info_df, left_on= ('patientId'), right_on=('patientId'), how='inner').drop_duplicates()\n",
    "train_class_df.sample(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAhldo8d0O71",
    "outputId": "eda8e48b-16d0-4c26-9dcc-caed2bc1d7d6"
   },
   "outputs": [],
   "source": [
    "#reading image 500 samples traindir\n",
    "sampNum = 500 # Number of samples to import\n",
    "X = [] # Empty to read training images\n",
    "x1=[]\n",
    "print(type(x1))\n",
    "print(\"Before sampling\\n\")\n",
    "print(\"Total training unique patient ids: \",train_class_df['patientId'].nunique())\n",
    "print(\"Number of images in train set:\", len(os.listdir(TrainDir)))\n",
    "print(\"\\n\")\n",
    "print(\"Total training labels {}\" .format(train_class_df.shape))\n",
    "#display(distTab(train_class_df, \"Target\")) # Dsitribution of target before sampling\n",
    "\n",
    "print(\"\\n\\nAfter sampling\\n\")\n",
    "Y = train_class_df.sample(n=sampNum, random_state=2) # Sampling\n",
    "Y.reset_index(drop=True, inplace=True)\n",
    "print(\"Total sampled training labels {}\" .format(Y.shape))\n",
    "#display(distTab(Y.sample(n=sampNum), \"Target\"))  # Dsitribution of target after sampling\n",
    "\n",
    "for indx in Y.patientId:\n",
    "    \n",
    "    try:\n",
    "       #print(indx)\n",
    "       filepath=TrainDir+indx+'.jpg'\n",
    "       image = cv2.imread(filepath)\n",
    "       X.append(indx)\n",
    "       x1.append(image)\n",
    "      # print(filepath)\n",
    "    except: \n",
    "        continue\n",
    "zipbObj = zip(X, x1)        \n",
    " \n",
    "\n",
    "X=dict(zipbObj)#takes zip object\n",
    "print(\"\\n\\nTotal sampled training images {}\" .format(len(X)))\n",
    "Y = Y[Y.patientId.isin(X.keys())]\n",
    "print(\"Total training labels {}\" .format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoDQeqijuLIu",
    "outputId": "9b8994eb-7805-4518-da2c-9cde53e6e9eb"
   },
   "outputs": [],
   "source": [
    "#reading image 100 samples test dir\n",
    "sampNum = 10 # Number of samples to import\n",
    "Xtest = [] # Empty to read training images\n",
    "x1test=[] \n",
    "#print(\"Total training unique patient ids: \",train_class_df['patientId'].nunique())\n",
    "print(\"Total training unique patient ids: \",sub_info_df['patientId'].nunique())\n",
    "print(\"Number of images in test set:\", len(os.listdir(TestDir)))\n",
    " \n",
    "print(\"\\n\")\n",
    "print(\"Total training labels {}\" .format(sub_info_df.shape))\n",
    "#print(\"Total training labels {}\" .format(train_class_df.shape))\n",
    "#Ytest = train_class_df.sample(n=sampNum, random_state=2) # Sampling\n",
    "Ytest = sub_info_df.sample(n=sampNum, random_state=2) # Sampling\n",
    "Ytest.reset_index(drop=True, inplace=True)\n",
    "print(\"Total sampled testing labels {}\" .format(Ytest.shape))\n",
    "#display(distTab(Y.sample(n=sampNum), \"Target\"))  # Dsitribution of target after sampling\n",
    "\n",
    "for indx1 in Ytest.patientId:\n",
    "    \n",
    "    try:\n",
    "      # print(indx1)\n",
    "       filepath1=TestDir+indx1+'.jpg'\n",
    "       image1 = cv2.imread(filepath1)\n",
    "       Xtest.append(indx1)\n",
    "       x1test.append(image1)\n",
    "      # print(filepath1)\n",
    "    except: \n",
    "        continue\n",
    "zipbObj1 = zip(Xtest, x1test)        \n",
    " \n",
    "\n",
    "Xtest=dict(zipbObj1)#takes list object\n",
    "#print(Xtest)\n",
    "print(\"\\n\\nTotal sampled test images {}\" .format(len(Xtest)))\n",
    "Ytest = Ytest[Ytest.patientId.isin(Xtest.keys())]\n",
    "print(\"Total test labels {}\" .format(Ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9crb-bARKlo",
    "outputId": "9c919fae-9b5d-452a-e0dd-acdec5183253"
   },
   "outputs": [],
   "source": [
    "# Shape of images\n",
    "print(len(X))\n",
    "print(len(Xtest))\n",
    "print(len(Y))\n",
    "print(len(Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voEK2fN724Dv"
   },
   "outputs": [],
   "source": [
    "Xdf = pd.DataFrame({'patientId':X.keys(),\n",
    "                   'imageArray':X.values()})\n",
    "dattrain = Y.merge(Xdf, on='patientId', how='left')\n",
    "\n",
    "#test\n",
    "Xtestdf = pd.DataFrame({'patientId':Xtest.keys(),\n",
    "                   'imageArray':Xtest.values()})\n",
    "dattest = Ytest.merge(Xtestdf, on='patientId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "id": "P-CkAjYf4Ap6",
    "outputId": "c175b874-3c76-46b0-d9d2-8f732c4a18bc"
   },
   "outputs": [],
   "source": [
    "dattrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "H0dHvXnUZTwe",
    "outputId": "63a75dca-40f0-4028-9f11-eb7369d198f3"
   },
   "outputs": [],
   "source": [
    " dattest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhfaCayKBSR6"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#test_class_df = y_train.merge(sub_info_df, left_on= ('patientId'), right_on=('patientId'), how='inner').drop_duplicates()\n",
    "#train_class_df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZIS3CrzYcSL"
   },
   "source": [
    "MSK RCC model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYdY9QZBZTzG",
    "outputId": "fa1e7f79-28f6-40cd-e716-c8c13feadb0d"
   },
   "outputs": [],
   "source": [
    "#download from  git\n",
    "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
    "os.chdir('Mask_RCNN')\n",
    "!python setup.py -q install\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "0x3-MPvEZT2Z",
    "outputId": "f65e0a2a-a938-4937-bdc7-a1b10189089a"
   },
   "outputs": [],
   "source": [
    "# Import Mask RCNN in root folder\n",
    "\n",
    "import sys,os\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "print(ROOT_DIR)\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append(os.path.join(basepath, 'Mask_RCNN'))  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from tensorflow.keras.layers import InputLayer, Input\n",
    "import mrcnn.utils as utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A32Qd-qsiwgO",
    "outputId": "30ece73f-9eef-4b73-e5be-a463c422f5db"
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0NA5VYGaKC5",
    "outputId": "a94d4cbd-1a25-46bd-a27d-326a982e6213"
   },
   "outputs": [],
   "source": [
    "#download weights\n",
    "### Download COCO pre-trained weights\n",
    "#!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
    "#!ls -lh mask_rcnn_coco.h5\n",
    "\n",
    "COCO_WEIGHTS_PATH = basepath+\"mask_rcnn_coco.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img and annotation looping\n",
    "def get_img_fps(img_dir):\n",
    "    img_fps = glob.glob(img_dir+'*.jpg')\n",
    "    return list(set(img_fps))\n",
    "\n",
    "def parse_dataset(img_dir, anns): \n",
    "    image_fps = get_img_fps(img_dir)\n",
    "    print(image_fps)\n",
    "    image_annotations = {fp: [] for fp in image_fps}\n",
    "    for index, row in anns.iterrows(): \n",
    "        fp = os.path.join(img_dir, row['patientId']+'.jpg')  #need to check this code\n",
    "        image_annotations[fp].append(row)\n",
    "    return image_fps, image_annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorConfig(Config):\n",
    "    \"\"\"Configuration for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    Overrides values in the base Config class.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Give the configuration a recognizable name  \n",
    "    NAME = 'pneumonia'\n",
    "    \n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "    \n",
    "    BACKBONE = 'resnet50'\n",
    "    \n",
    "    NUM_CLASSES = 2  # background + 1 pneumonia classes\n",
    "    \n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256)\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "    MAX_GT_INSTANCES = 3\n",
    "    DETECTION_MAX_INSTANCES = 3\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    DETECTION_NMS_THRESHOLD = 0.1\n",
    "\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    \n",
    "config = DetectorConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorDataset(utils.Dataset):\n",
    "    \"\"\"Dataset class for training pneumonia detection on the RSNA pneumonia dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_fps, image_annotations, orig_height, orig_width):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        # Add classes\n",
    "        self.add_class('pneumonia', 1, 'Lung Opacity')\n",
    "        \n",
    "        # add images \n",
    "        for i, fp in enumerate(image_fps):\n",
    "            annotations = image_annotations[fp]\n",
    "            self.add_image('pneumonia', image_id=i, path=fp, \n",
    "                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)\n",
    "            \n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        fp = info['path']\n",
    "        ds = pydicom.read_file(fp)\n",
    "        image = ds.pixel_array\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "            image = np.stack((image,) * 3, -1)\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info['annotations']\n",
    "        count = len(annotations)\n",
    "        if count == 0:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)\n",
    "            class_ids = np.zeros((1,), dtype=np.int32)\n",
    "        else:\n",
    "            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)\n",
    "            class_ids = np.zeros((count,), dtype=np.int32)\n",
    "            for i, a in enumerate(annotations):\n",
    "                if a['Target'] == 1:\n",
    "                    x = int(a['x'])\n",
    "                    y = int(a['y'])\n",
    "                    w = int(a['width'])\n",
    "                    h = int(a['height'])\n",
    "                    mask_instance = mask[:, :, i].copy()\n",
    "                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)\n",
    "                    mask[:, :, i] = mask_instance\n",
    "                    class_ids[i] = 1\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fps, image_annotations = parse_dataset(TrainDir, anns=anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "id": "xt8fGSygaKGR",
    "outputId": "d5afe407-3f4e-4d63-dfa8-3e0dcecb7602"
   },
   "outputs": [],
   "source": [
    "hyper_paramters_comb={\n",
    "    'backbone':['resnet50'],\n",
    "    'learning_rate':[0.005],\n",
    "    'batch_size':[8],\n",
    "    'epochs':[10],\n",
    "    'det_min_conf':[0.9],\n",
    "    'det_nms_th':[0.8],\n",
    "    'rpn_nms_th':[0.7],\n",
    "    'steps_per_epoch':[135],\n",
    "    'layers': ['heads']\n",
    "}\n",
    "\n",
    "hpc=pd.DataFrame(hyper_paramters_comb)\n",
    "\n",
    "hpc['learning_rate'] = hpc['learning_rate'].astype(np.float32)\n",
    "hpc['det_min_conf'] = hpc['det_min_conf'].astype(np.float32)\n",
    "hpc['det_nms_th'] = hpc['det_nms_th'].astype(np.float32)\n",
    "hpc['rpn_nms_th'] = hpc['rpn_nms_th'].astype(np.float32)\n",
    "\n",
    "hpc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "LXIhXa4NZSqa",
    "outputId": "98cc2f65-2984-49d8-b666-b496b5d7ce7e"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 16\n",
    "LEARNING_RATE = 0.006\n",
    "\n",
    "# Train Mask-RCNN Model \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = modellib.MaskRCNN(mode='training', config=config, model_dir=modeldir)\n",
    "\n",
    "# Exclude the last layers because they require a matching number of classes\n",
    "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
    "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg1F1UDQZE6x"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## first epochs with higher lr to speedup the learning\n",
    "model.train(dattrain, dattest,\n",
    "            learning_rate=LEARNING_RATE*2,\n",
    "            epochs=2,\n",
    "            layers='all',\n",
    "            augmentation=None)  ## no need to augment yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# select trained model \n",
    "dir_names = next(os.walk(model.model_dir))[1]\n",
    "key = config.NAME.lower()\n",
    "dir_names = filter(lambda f: f.startswith(key), dir_names)\n",
    "dir_names = sorted(dir_names)\n",
    "\n",
    "if not dir_names:\n",
    "    import errno\n",
    "    raise FileNotFoundError(\n",
    "        errno.ENOENT,\n",
    "        \"Could not find model directory under {}\".format(self.model_dir))\n",
    "    \n",
    "fps = []\n",
    "# Pick last directory\n",
    "for d in dir_names: \n",
    "    dir_name = os.path.join(model.model_dir, d)\n",
    "    # Find the last checkpoint\n",
    "    checkpoints = next(os.walk(dir_name))[2]\n",
    "    checkpoints = filter(lambda f: f.startswith(\"mask_rcnn\"), checkpoints)\n",
    "    checkpoints = sorted(checkpoints)\n",
    "    if not checkpoints:\n",
    "        print('No weight files in {}'.format(dir_name))\n",
    "    else:\n",
    "        checkpoint = os.path.join(dir_name, checkpoints[-1])\n",
    "        fps.append(checkpoint)\n",
    "\n",
    "model_path = sorted(fps)[-1]\n",
    "print('Found model {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Capstoneyolomodel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
